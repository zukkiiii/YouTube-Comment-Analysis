{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zukkiii_\\Anaconda3\\lib\\site-packages\\tqdm\\autonotebook\\__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fddf4063748406faa24e2312c2fefca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=198, style=ProgressStyle(description_widthâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Table created successfully\n",
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import swifter\n",
    "from Database import database\n",
    "import Database\n",
    "from Connection import connection\n",
    "from Preprocessing import preprocessing\n",
    "\n",
    "\n",
    "con = connection.connect(Database.params_dic)\n",
    "\n",
    "column_names = [\"user_name\", \"comments_user\", \"video_title\", \"channel\", \"views\", \"posted\"]\n",
    "\n",
    "df = database.postgresql_to_dataframe(con, \"select * from youtube_comments\", column_names)\n",
    "\n",
    "con.close()\n",
    "\n",
    "df = df.drop_duplicates(['user_name', 'comments_user', 'posted'])\n",
    "\n",
    "df['comments_clean'] = pd.DataFrame(df['comments_user'].apply(lambda x: preprocessing.clean_text(x)))\n",
    "\n",
    "v = df['comments_clean'].str.split().tolist()\n",
    "c = Counter(chain.from_iterable(v))\n",
    "df['comments_clean']=[' '.join([j for j in i if c[j] > 1]) for i in v]\n",
    "\n",
    "df['comments_tokenize'] = pd.DataFrame(df['comments_clean'].apply(lambda x: preprocessing.tokenize(x)))\n",
    "\n",
    "df['comments_slangword'] = pd.DataFrame(df['comments_tokenize'].apply(lambda x: preprocessing.slangword(x)).apply(lambda x: preprocessing.tokenize(x)))\n",
    "\n",
    "term_dict = {}\n",
    "for document in df['comments_slangword']:\n",
    "    for term in document:\n",
    "        if term not in term_dict:\n",
    "            term_dict[term] = ' '\n",
    "\n",
    "for term in term_dict:\n",
    "    term_dict[term] = preprocessing.stemmed_wrapper(term)\n",
    "    \n",
    "def get_stemmed_term(document):\n",
    "        return [term_dict[term] for term in document]\n",
    "    \n",
    "df['comments_stemmed'] = df['comments_slangword'].swifter.apply(get_stemmed_term)\n",
    "\n",
    "df['comments_stopwords'] = pd.DataFrame(df['comments_stemmed'].apply(lambda x : preprocessing.stopwords(x)).apply(lambda x: preprocessing.tokenize(x)))\n",
    "\n",
    "df['text_string'] = pd.DataFrame(df['comments_stemmed'].apply(lambda x : preprocessing.stopwords(x)))\n",
    "\n",
    "df['text_string'] = df['text_string'].str.strip().replace('',np.nan)\n",
    "\n",
    "df = df.dropna(how='any', axis=0).reset_index()\n",
    "\n",
    "df.columns = [\"document_no\",\"user_name\", \"comments_user\", \"video_title\", \"channel\", \"views\", \"posted\", \"comments_clean\",\n",
    "              \"comments_tokenize\", \"comments_slangword\", \"comments_stemmed\", \"comments_stopwords\", \"text_string\"]\n",
    "\n",
    "#df = df.reset_index()\n",
    "\n",
    "#df.columns = [\"document_no\",\"user_name\", \"comments_user\", \"video_title\", \"channel\", \"views\", \"posted\", \"comments_clean\",\n",
    "              #\"comments_tokenize\", \"comments_slangword\", \"comments_stemmed\", \"comments_stopwords\", \"text_string\"]\n",
    "\n",
    "df.to_csv(Database.path_data + 'youtube_comments_preprocessing.csv', encoding=\"UTF-8\", sep=',', index=False)\n",
    "\n",
    "database.createTableDatabasePreprocessing()\n",
    "database.intoDatabasePreprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_string'] = df['text_string'].str.strip().replace('',np.nan)\n",
    "\n",
    "df = df.dropna(how='any', axis=0).reset_index()\n",
    "\n",
    "df.columns = [\"document_no\",\"user_name\", \"comments_user\", \"video_title\", \"channel\", \"views\", \"posted\", \"comments_clean\",\n",
    "              \"comments_tokenize\", \"comments_slangword\", \"comments_stemmed\", \"comments_stopwords\", \"text_string\"]\n",
    "\n",
    "#df = df.reset_index()\n",
    "\n",
    "#df.columns = [\"document_no\",\"user_name\", \"comments_user\", \"video_title\", \"channel\", \"views\", \"posted\", \"comments_clean\",\n",
    "              #\"comments_tokenize\", \"comments_slangword\", \"comments_stemmed\", \"comments_stopwords\", \"text_string\"]\n",
    "\n",
    "df.to_csv(Database.path_data + 'youtube_comments_preprocessing.csv', encoding=\"UTF-8\", sep=',', index=False)\n",
    "\n",
    "database.createTableDatabasePreprocessing()\n",
    "database.intoDatabasePreprocessing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
